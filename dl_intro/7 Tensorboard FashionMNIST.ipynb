{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch and TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we’ll learn how to:\n",
    "\n",
    "1. Read in data and with appropriate transforms (nearly identical to the prior tutorial).\n",
    "- Set up TensorBoard.\n",
    "- Write to TensorBoard.\n",
    "- Inspect a model architecture using TensorBoard.\n",
    "- Use TensorBoard to create interactive versions of the visualizations we created in last tutorial, with less code\n",
    "\n",
    "\n",
    "Specifically, on point `5`, we will see:\n",
    "\n",
    "- Two ways to inspect our training data\n",
    "- How to track our model’s performance as it trains\n",
    "- How to assess our model’s performance once it is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "\n",
    "Of course, you could do everything TensorBoard does in your Jupyter Notebook, but with TensorBoard, you gets visuals that are interactive by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a similar model architecture from that tutorial, making only minor modifications to account for the fact that the images are now one channel instead of three and 28x28 instead of 32x32:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define the same `optimizer` and `criterion` from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll set up TensorBoard, importing `tensorboard` from `torch.utils` and defining a `SummaryWriter`, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this line alone creates a `runs/fashion_mnist_experiment_1` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing To TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tensorboard\n",
    "\n",
    "Now running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tensorboard --logdir=runs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to use TensorBoard! \n",
    "\n",
    "$\\rightarrow$ [http://localhost:6006](http://localhost:6006)\n",
    "\n",
    "This example, however, could be done in a Jupyter Notebook - where TensorBoard really excels is in creating interactive visualizations. We’ll cover one of those next, and several more by the end of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upon refreshing TensorBoard you should see a **Graphs** tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and double click on “Net” to see it expand, seeing a detailed view of the individual operations that make up the model.\n",
    "\n",
    "TensorBoard has a very handy feature for visualizing high dimensional data such as image data in a lower dimensional space; we’ll cover this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a “Projector” to TensorBoard\n",
    "\n",
    "We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Patch\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the “Projector” tab of TensorBoard, you can see these 100 images - each of which is 784 dimensional - projected down into three dimensional space. Furthermore, this is interactive: you can click and drag to rotate the three dimensional projection. Finally, a couple of tips to make the visualization easier to see: select “color: label” on the top left, as well as enabling “night mode”, which will make the images easier to see since their background is white:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking model training with TensorBoard\n",
    "\n",
    "In the previous example, we simply printed the model’s running loss every `2000` iterations. \n",
    "\n",
    "Now, we’ll instead log the running loss to TensorBoard, along with a view into the predictions the model is making via the `plot_classes_preds` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s train the model using the same model training code from the prior tutorial, but writing results to TensorBoard every `1000` batches instead of printing to console; this is done using the `add_scalar` function.\n",
    "\n",
    "In addition, as we train, we’ll generate an image showing the model’s predictions vs. the actual results on the four images included in that batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now look at the scalars tab to see the running loss plotted over the `15,000` iterations of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can look at the predictions the model made on arbitrary batches throughout learning. See the “Images” tab and scroll down under the “predictions vs. actuals” visualization to see this; this shows us that, for example, after just 3000 training iterations, the model was already able to distinguish between visually distinct classes such as shirts, sneakers, and coats, though it isn’t as confident as it becomes later on in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tb_image](https://pytorch.org/tutorials/_static/img/tensorboard_images.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL-TORCH)",
   "language": "python",
   "name": "dl-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
