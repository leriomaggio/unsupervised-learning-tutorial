{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch `autograd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR**:\n",
    "\n",
    "(doc. reference: [torch autograd](https://pytorch.org/docs/stable/autograd.html))\n",
    "\n",
    "`torch.autograd` provides classes and functions implementing automatic differentiation of arbitrary scalar valued functions. \n",
    "\n",
    "It requires minimal changes to the existing code - you only need to declare `Tensor`s for which gradients should be computed with the `requires_grad=True` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Learning Process\n",
    "\n",
    "![learning process sketch](./learning_process.png)\n",
    "\n",
    "<span class=\"fn\"><i>Source:</i> [1] - _Deep Learning with PyTorch_ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: `numpy` ol' friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy does not know **anything** about computation graphs, or deep learning, or gradients. \n",
    "\n",
    "However we can easily use `numpy` to fit a two-layer network to random data by **manually** implementing the `forward` and `backward` passes through the network using numpy primitives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`relu(x) = max(0, x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34755040.37113127\n",
      "50 16736.657744131237\n",
      "100 722.420953140567\n",
      "150 52.20013726385122\n",
      "200 4.371520347473859\n",
      "250 0.38916586233894057\n",
      "300 0.03580886615729533\n",
      "350 0.0033655781177274486\n",
      "400 0.0003212273862653529\n",
      "450 3.1039598298967795e-05\n",
      "Final Loss:  3.1754789264702773e-06\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 50 == 0:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "print('Final Loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.Tensor`\n",
    "\n",
    "``torch.Tensor`` is the central class of the package. \n",
    "\n",
    "Numpy is a great framework, but it cannot utilize GPUs to accelerate its numerical computations. For modern deep neural networks, GPUs often provide speedups of **50x or greater** ([some benchmark here](https://github.com/jcjohnson/cnn-benchmarks)), so unfortunately `numpy` won’t be enough for modern deep learning.\n",
    "\n",
    "Let's rewrite the previous example using `torch.Tensor` and PyTorch API to _manually_ implement the forward and backward passes through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43086612.0\n",
      "50 14417.1572265625\n",
      "100 666.0763549804688\n",
      "150 60.01008605957031\n",
      "200 7.783235549926758\n",
      "250 1.22281813621521\n",
      "300 0.21154741942882538\n",
      "350 0.03857883810997009\n",
      "400 0.0074922144412994385\n",
      "450 0.0017392367590218782\n",
      "Final Loss:  0.0005412618047557771\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)  # x * w\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 50 == 0:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    \n",
    "print('Final Loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above examples, we had to manually implement both the forward and backward passes of our neural network. \n",
    "\n",
    "Manually implementing the backward pass is **not** ideal for networks bigger than just two layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.autograd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `autograd` package in PyTorch provides exactly this functionality. \n",
    "\n",
    "When using autograd, the forward pass of your network will define a **(dynamic) computational graph**;\n",
    "_nodes_ in the graph will be _Tensors_, and _edges_ will be functions that produce output _Tensors_ from input _Tensors_. \n",
    "\n",
    "Backpropagating through this graph then allows to easily compute gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `torch.autograd` & `torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you set its attribute ``.requires_grad`` as ``True``, it starts to track all operations on it. \n",
    "\n",
    "When you finish your computation you can call ``.backward()`` and have all the\n",
    "gradients computed automatically. \n",
    "\n",
    "The gradient for this tensor will be accumulated into ``.grad`` attribute.\n",
    "\n",
    "To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
    "it from the computation history, and to prevent future computation from being\n",
    "tracked.\n",
    "\n",
    "To prevent tracking history (and using memory), you can also wrap the code block\n",
    "in ``with torch.no_grad():``. \n",
    "\n",
    "This can be particularly helpful when evaluating a model because the model may have trainable parameters with ``requires_grad=True``, but for which we don't need the gradients.\n",
    "\n",
    "There’s one more class which is very important for autograd implementation: a ``Function``.\n",
    "\n",
    "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. \n",
    "\n",
    "Each tensor has a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Tensor`` (except for Tensors created by the user - their ``grad_fn is None``).\n",
    "\n",
    "If you want to compute the derivatives, you can call ``.backward()`` on a ``Tensor``. \n",
    "\n",
    "If ``Tensor`` is a scalar, you don’t need to specify any arguments to ``backward()``,\n",
    "however if it has more elements, you need to specify a ``gradient``\n",
    "argument that is a tensor of matching shape.\n",
    "\n",
    "---\n",
    "<span id=\"fn1\">Source: [PyTorch Autograd Tutorial](https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/autograd_tutorial.py)</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor requiring a gradient\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's use this tensor in a function\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x109cb5d50>\n"
     ]
    }
   ],
   "source": [
    "# y was created as a result of an operation, so it has a ``grad_fn``.\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's do more operations on y\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `tensor.requires_grad_` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad`` flag in-place. \n",
    "\n",
    "The input flag defaults to ``False`` if not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x11fe40ed0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradients\n",
    "\n",
    "Let's backprop now!\n",
    "\n",
    "Because ``out`` contains a single scalar, ``out.backward()`` is equivalent to ``out.backward(torch.tensor(1.))``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data  # `.data` property returns the data of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You should have got a matrix of ``4.5``. \n",
    " \n",
    " Let’s call the ``out`` *Tensor* $o$.\n",
    "\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$, $z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "\n",
    "Therefore, $\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, \n",
    "hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few notes about `tensor.backward` and non-leaf tensors\n",
    "\n",
    "```python\n",
    "tensor.backward(gradient=None, retain_graph=None, create_graph=False)\n",
    "```\n",
    "\n",
    "[`tensor.backward`](https://pytorch.org/docs/stable/_modules/torch/tensor.html#Tensor.backward) \n",
    "computes the gradient of current tensor w.r.t. graph leaves.\n",
    "\n",
    "The graph is differentiated using the chain rule. \n",
    "\n",
    "If the tensor is non-scalar (i.e. its data has more than one element) and requires gradient, the function additionally requires specifying gradient. \n",
    "\n",
    "It should be a tensor of matching type and location, that contains the gradient of the differentiated function w.r.t. self.\n",
    "\n",
    "This function accumulates gradients in the **leaves** - you might need to zero them before calling it.\n",
    "\n",
    "**Parameters**:\n",
    "\n",
    "- `gradient` (Tensor or None): Gradient w.r.t. the\n",
    "    tensor. If it is a tensor, it will be automatically converted\n",
    "    to a Tensor that does not require grad unless ``create_graph`` is True.\n",
    "    None values can be specified for scalar Tensors or ones that\n",
    "    don't require grad. If a None value would be acceptable then\n",
    "    this argument is optional.\n",
    "    \n",
    "- `retain_graph` (bool, optional): If ``False``, the graph used to compute\n",
    "    the grads will be freed. Note that in nearly all cases setting\n",
    "    this option to True is not needed and often can be worked around\n",
    "    in a much more efficient way. Defaults to the value of\n",
    "    ``create_graph``.\n",
    "\n",
    "- `create_graph` (bool, optional): If ``True``, graph of the derivative will\n",
    "  be constructed, allowing to compute higher order derivative\n",
    "  products. Defaults to ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gu19087/opt/anaconda3/envs/dl-torch/lib/python3.7/site-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
     ]
    }
   ],
   "source": [
    "# this is supposed to raise a warning\n",
    "out.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `backward` and Dynamic Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient enabled tensors (a.k.a. `variables`) along with functions (`operations`) combine to create the dynamic computational graph. \n",
    "The flow of data and the operations applied to the data are defined at runtime hence constructing the computational graph dynamically. \n",
    "\n",
    "This graph is made dynamically by the `autograd` class under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple DCG for multiplication of two tensors would look like this:\n",
    "\n",
    "![DCG Example](https://miro.medium.com/max/672/1*jGo_2J9UQeynwG_3olUD4w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dotted outline box in the graph is a variable and the purple rectangular box is an operation.\n",
    "\n",
    "Every variable object has several members some of which are:\n",
    "\n",
    "`data`: It’s the data a variable is holding. \n",
    "\n",
    "`requires_grad`: if true starts tracking all the operation history and forms a backward graph for gradient calculation. \n",
    "\n",
    "`grad`: grad holds the value of gradient. If `requires_grad` is `False` it will hold a `None` value. Even if `requires_grad` is `True`, it will hold a `None` value unless `.backward()` function is called from some other node. \n",
    "For example, if you call `out.backward()` for some variable out that involved `x` in its calculations then `x.grad` will hold $\\frac{\\partial out}{\\partial x}$.\n",
    "\n",
    "`grad_fn`: This is the backward function used to calculate the gradient.\n",
    "\n",
    "`is_leaf`: A node is a **leaf** if:\n",
    "    - It was initialized explicitly by some factory method (e.g. `x = torch.randn(1, 1)`).\n",
    "    - It is created after operations on tensors which all have `requires_grad=False`.\n",
    "    - It is created by calling `.detach()` method on some tensor (see below).\n",
    "\n",
    "On calling `backward()`, gradients are populated only for the nodes which have both `requires_grad` **and** `is_leaf=True`. \n",
    "\n",
    "Gradients are of the output node from which `.backward()` is called, w.r.t other leaf nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On turning `requires_grad=True` PyTorch will start tracking the operation and store the gradient functions at each step as follows:\n",
    "\n",
    "![DCG Gradient](https://miro.medium.com/max/942/1*viCEZbSODfA8ZA4ECPwHxQ.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithmically, here is how backpropagation happens with a computation graph. \n",
    "\n",
    "> (Not the actual implementation, only representative)\n",
    "\n",
    "```python\n",
    "\n",
    "def backward (incoming_gradients):\n",
    "\tself.Tensor.grad = incoming_gradients\n",
    "\n",
    "\tfor inp in self.inputs:\n",
    "\t\tif inp.grad_fn is not None:\n",
    "\t\t\tadjont = incoming_gradient * local_grad(self.Tensor, inp)\n",
    "\t\t\tinp.grad_fn.backward(adjont)\n",
    "\t\telse:\n",
    "\t\t\tcontinue\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Try to generate the code that has produced that above graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a5a1135db291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# what if we try to re-run backward once again ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dl-torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl-torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "out.retain_grad()\n",
    "\n",
    "# what if we try to re-run backward once again ?\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try again\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "out.retain_grad()\n",
    "\n",
    "out.backward(create_graph=True, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 9.],\n",
       "        [9., 9.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first of all let's have a look at the grad \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `gradient` has been **accumulated**, not replaced! \n",
    "\n",
    "This will explain **why** we need to `zero_grad` the gradient of model parameters before applying a \n",
    "new step in the `optimiser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], grad_fn=<ZeroBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to zero the gradient of a tensor\n",
    "x.grad.zero_()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()  # this won't complain now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]], grad_fn=<ZeroBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.grad  # this should be 1 - we did not zero the grad after a second step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad  # this will fail as we are **not** retaining the grad for \"internal\" tensors (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detaching the Gradient (`Variable` $\\mapsto$ `Tensor`)\n",
    "\n",
    "###### `Variable`: Sorry what?\n",
    "\n",
    "\n",
    "`Variable` (**now [deprecated](https://pytorch.org/docs/stable/autograd.html#variable-deprecated)**) were initially used to differentiate `Tensor` objects that were used as input to the `autograd` module. \n",
    "\n",
    "In other words, it was necessary to convert a `tensor` into a `Variable` in order to use `autograd`.\n",
    "\n",
    "This (explicit) transformation is **no longer** necessary!\n",
    "\n",
    "This distinction was indeed confusing - reminds the very same sort of confusion that what happening in TF to distinguish between `Variable` and `placeholder` (see [here](https://stackoverflow.com/questions/36693740/whats-the-difference-between-tf-placeholder-and-tf-variable)).\n",
    "\n",
    "`Variable(tensor)`, and `Variable(tensor, requires_grad=True)` still work but they do now return a `Tensor` rather than a `Variable`.\n",
    "\n",
    "In addition, factory methods to create `Tensor` such as `torch.randn()`, `torch.zeros()`, `torch.ones()`, and others include the `requires_grad` parameter:\n",
    "\n",
    "```python\n",
    "autograd_tensor = torch.randn((2, 3, 4), requires_grad=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always possible to instruct `autograd` to stop from tracking history on Tensors with `.requires_grad=True` either by wrapping the code block in with `torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using `.detach()` to get a **new** Tensor with the same content but that does not require gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on `detach`** (see [doc](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach))\n",
    "\n",
    "> Returned Tensor shares the same storage with the original one. In-place modifications on either of them will be seen, and may trigger errors in correctness checks. \n",
    ">\n",
    "> IMPORTANT NOTE: Previously, in-place `size` | `stride` | `storage` changes \n",
    "> (such as `resize_` | `resize_as_` | `set_` | `transpose_`) to the returned tensor \n",
    "also update the original tensor. \n",
    "> Now, these in-place changes will not update the original tensor anymore, and will instead trigger an error. For sparse tensors: In-place indices / values changes (such as `zero_` | `copy_` | `add_`) to the returned tensor will not update the original tensor anymore, and will instead trigger an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Layer Network (MLP) using (built-in) `torch.autograd`\n",
    "\n",
    "So, now going back to our previous example, let's rewrite our code in order to exploit the integrated `autograd` engine to calculate the gradients, without having to manually write the **backward** pass through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Tensors during the backward pass.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we're going to **require gradient** (i.e. `required_grad=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random Tensors for weights.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31321970.0\n",
      "50 16129.734375\n",
      "100 708.8333740234375\n",
      "150 50.95680236816406\n",
      "200 4.466130256652832\n",
      "250 0.4328244924545288\n",
      "300 0.04436235502362251\n",
      "350 0.0049266270361840725\n",
      "400 0.0007668549078516662\n",
      "450 0.00020471203606575727\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: \n",
    "    # ============\n",
    "    # compute predicted y using operations on Tensors;\n",
    "    # these are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand!\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor [of shape (1,)]\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 50 == 0:\n",
    "        print(t, loss.item())  # loss.item() gets the scalar value held in the loss.\n",
    "\n",
    "    # Backward pass: \n",
    "    # =============\n",
    "    # Use autograd to compute the backward pass. \n",
    "    # This call will compute the gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call `w1.grad` and `w2.grad` will be Tensors holding the gradient\n",
    "    # of the loss with respect to `w1` and `w2`, respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameters Update (still manual)\n",
    "    # =================\n",
    "    # Manually update weights using gradient descent. \n",
    "    # NOTE: \n",
    "    # Using torch.no_grad()\n",
    "    # because weights have `requires_grad=True`, but we don't need to track this\n",
    "    # in autograd.\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    \n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # We will use torch.optim.SGD later for the optimisation step.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Addendum**: [TensorFlow 1.x Static Graph](addendum_tf_static_graph.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### References and Futher Reading:\n",
    "\n",
    "1. [(*Paper*) PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf)\n",
    "2. [PyTorch Autograd Function](https://pytorch.org/docs/stable/autograd.html#function)\n",
    "3. [(**Terrific**) PyTorch Examples Repo](https://github.com/jcjohnson/pytorch-examples) (*from which, most of the examples in this section have been taken*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL-TORCH)",
   "language": "python",
   "name": "dl-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
